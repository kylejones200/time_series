{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae4560b",
   "metadata": {},
   "source": [
    "# Neural Networks for Time SeriesÂ Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66451d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d400216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numpy-1.24.4\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "time = pd.date_range(start='2023-01-01', periods=1000, freq='D')\n",
    "data = 10 + 0.5 * np.arange(len(time)) + np.sin(0.2 * np.arange(len(time))) + np.random.normal(scale=1.0, size=len(time))\n",
    "df = pd.DataFrame({'date': time, 'value': data})\n",
    "\n",
    "# Create lagged features\n",
    "def create_features(df, lag=3):\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f'lag_{i}'] = df['value'].shift(i)\n",
    "    return df.dropna()\n",
    "\n",
    "lag = 3\n",
    "df_features = create_features(df, lag=lag)\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df_features.drop(['date', 'value'], axis=1)\n",
    "y = df_features['value']\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Define the model\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = []\n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "\n",
    "for train_index, test_index in ts_cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Scale the features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Fit the model and make predictions\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate the score\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    # Store actual and predicted values\n",
    "    all_y_test.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average RMSE\n",
    "rmse = np.sqrt(np.mean(cv_scores))\n",
    "rmse_std = np.sqrt(np.std(cv_scores))\n",
    "print(f\"RMSE = {rmse:.3f} +/- {rmse_std:.3f}\")\n",
    "\n",
    "\"\"\"# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_features['date'].iloc[lag:], all_y_test, label='Actual', color='Blue')\n",
    "plt.plot(df_features['date'].iloc[lag:], all_y_pred, label='Predicted', color='Red')\n",
    "plt.title('Neural Network Forecast with TimeSeriesSplit')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"NN_forecast_timeseries.png\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ... (rest of your code remains the same until the plotting part)\n",
    "\n",
    "# Plot the results\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(go.Scatter(x=df_features['date'].iloc[lag:], y=all_y_test, name='Actual', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=df_features['date'].iloc[lag:], y=all_y_pred, name='Predicted', line=dict(color='red')))\n",
    "fig.update_layout(title='Neural Network Forecast with TimeSeriesSplit', xaxis_title='Date', yaxis_title='Value')\n",
    "fig.write_image(\"NN_forecast_timeseries.png\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e05fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to T10Y2Y_data.csv\n",
      "Data read successfully.\n",
      "           realtime_start realtime_end  value\n",
      "date                                         \n",
      "2000-01-03     2025-01-08   2025-01-08   0.20\n",
      "2000-01-04     2025-01-08   2025-01-08   0.19\n",
      "2000-01-05     2025-01-08   2025-01-08   0.24\n",
      "2000-01-06     2025-01-08   2025-01-08   0.22\n",
      "2000-01-07     2025-01-08   2025-01-08   0.21\n",
      "Number of rows after reading CSV: 6257\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-830a0a1f5e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Create lagged features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Prepare data for modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6359\u001b[0m                     )\n\u001b[1;32m   6360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6361\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6362\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6363\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4822\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4824\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_update_mgr_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_update_blklocs_and_blknos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_insert_update_blklocs_and_blknos\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0;31m# np.append is a lot faster, let's use it if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5442\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5443\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mravel\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mravel\u001b[0;34m(a, order)\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \"\"\"\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'matrix'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def load_config():\n",
    "    with open(\"main.yaml\", \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def fetch_fred_data(config):\n",
    "    \"\"\"Fetch data from FRED API and save to CSV.\"\"\"\n",
    "    params = {\n",
    "        'series_id': config['fred']['series_id'],\n",
    "        'api_key': config['fred']['api_key'],\n",
    "        'file_type': 'json',\n",
    "        'observation_start': config['fred']['start_date'],\n",
    "        'observation_end': datetime.now().strftime('%Y-%m-%d'),\n",
    "    }\n",
    "    url = config['fred']['api_url']\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        observations = data['observations']\n",
    "        df = pd.DataFrame(observations)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        \n",
    "        df = df.dropna()\n",
    "        df = df.sort_values('date')\n",
    "        df = df.set_index('date')\n",
    "        \n",
    "        csv_filename = f\"{config['fred']['series_id']}_data.csv\"\n",
    "        df.to_csv(csv_filename)\n",
    "        print(f\"Data saved to {csv_filename}\")\n",
    "        \n",
    "        return csv_filename\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "def read_fred_data(filename):\n",
    "    \"\"\"Read FRED data from CSV file.\"\"\"\n",
    "    df = pd.read_csv(filename, parse_dates=['date'])\n",
    "    return df.set_index('date')\n",
    "\n",
    "def create_features(df, lag=3):\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f'lag_{i}'] = df['value'].shift(i)\n",
    "    return df.dropna()\n",
    "\n",
    "def display_forecast(actual_series, pred_series, forecast_type, config):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    actual_series.plot(label=\"Actual\", color='blue')\n",
    "    pred_series.plot(label=f\"{forecast_type.capitalize()} Forecast\", color='red')\n",
    "    plt.title(f\"{config['fred']['series_id']}: {forecast_type.capitalize()} Forecast\\n\"\n",
    "              f\"R2: {r2_score(actual_series, pred_series):.4f}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(config['plot']['y_label'])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config['plot']['output_dir']}/MLP_{forecast_type}_Forecast.png\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = load_config()\n",
    "\n",
    "    # Fetch data from FRED and save to CSV\n",
    "    csv_filename = fetch_fred_data(config)\n",
    "\n",
    "    # Read data from CSV\n",
    "    df = read_fred_data(csv_filename)\n",
    "    print(\"Data read successfully.\")\n",
    "    print(df.head())\n",
    "    print(f\"Number of rows after reading CSV: {len(df)}\")\n",
    "\n",
    "    # Create lagged features\n",
    "    lag = config['data']['lag']\n",
    "    df_features = create_features(df.reset_index(), lag=lag)\n",
    "\n",
    "    # Prepare data for modeling\n",
    "    X = df_features[['lag_1', 'lag_2', 'lag_3']]\n",
    "    y = df_features['value']\n",
    "\n",
    "    # Initialize TimeSeriesSplit\n",
    "    ts_cv = TimeSeriesSplit(n_splits=min(config['model']['n_splits'], len(X) - 1))\n",
    "\n",
    "    # Initialize MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Define the model\n",
    "    model = MLPRegressor(**config['model']['mlp_params'])\n",
    "\n",
    "    # Perform cross-validation and generate forecasts\n",
    "    cv_scores = []\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "\n",
    "    for train_index, test_index in ts_cv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Scale the features\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Store predictions and actuals\n",
    "        all_predictions.extend(y_pred)\n",
    "        all_actuals.extend(y_test)\n",
    "        \n",
    "        # Calculate the score\n",
    "        score = mean_squared_error(y_test, y_pred)\n",
    "        cv_scores.append(score)\n",
    "\n",
    "    # Calculate and print the average RMSE\n",
    "    rmse = np.sqrt(np.mean(cv_scores))\n",
    "    rmse_std = np.sqrt(np.std(cv_scores))\n",
    "    print(f\"RMSE = {rmse:.3f} +/- {rmse_std:.3f}\")\n",
    "\n",
    "    # Create series for actual and predicted values\n",
    "    actual_series = pd.Series(all_actuals, index=df_features.index[-len(all_actuals):])\n",
    "    pred_series = pd.Series(all_predictions, index=df_features.index[-len(all_predictions):])\n",
    "\n",
    "    # Display the historical forecast\n",
    "    display_forecast(actual_series, pred_series, \"historical\", config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436130c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "works\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Generate future predictions\n",
    "future_steps = 30  # Number of future steps to predict\n",
    "last_known_values = X.iloc[-1].values.reshape(1, -1)\n",
    "future_predictions = []\n",
    "\n",
    "# Context manager to ignore the specific warning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    \n",
    "    for _ in range(future_steps):\n",
    "        # Scale the input\n",
    "        scaled_input = scaler.transform(last_known_values)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(scaled_input)\n",
    "        future_predictions.append(prediction[0])\n",
    "        \n",
    "        # Update last_known_values for next prediction\n",
    "        last_known_values = np.roll(last_known_values, -1)\n",
    "        last_known_values[0, -1] = prediction[0]\n",
    "\n",
    "# Create future dates\n",
    "last_date = df_features['date'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_steps)\n",
    "\n",
    "# Filter historical data since 2024\n",
    "start_date = datetime(2024, 1, 1)\n",
    "historical_data = df_features[df_features['date'] >= start_date]\n",
    "\n",
    "# Plot historical data and future predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(historical_data['date'], historical_data['value'], label='Historical Data', color='blue')\n",
    "plt.plot(future_dates, future_predictions, label='Future Predictions', color='red')\n",
    "plt.title(f\"{config['fred']['series_id']} Historical Data and Future Forecast\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(config['plot']['y_label'])\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"NN_forecast_future.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print future predictions\n",
    "future_df = pd.DataFrame({'Date': future_dates, 'Predicted Value': future_predictions})\n",
    "\n",
    "print(\"Forecasting completed and visualizations saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5342f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Error in sys.excepthook:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "Original exception was:\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap>\", line 194, in _lock_unlock_module\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/posixpath.py\", line 392, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/jnesnky/opt/anaconda3/lib/python3.8/posixpath.py\", line 360, in normpath\n",
      "    if (comp != dotdot or (not initial_slashes and not new_comps) or\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70a65523f8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_missing_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_missing_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Generate future predictions\n",
    "future_steps = 30  # Number of future steps to predict\n",
    "last_known_values = X.iloc[-1].values.reshape(1, -1)\n",
    "future_predictions = []\n",
    "prediction_std = []\n",
    "\n",
    "# Context manager to ignore the specific warning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    \n",
    "    for step in range(future_steps):\n",
    "        # Scale the input\n",
    "        scaled_input = scaler.transform(last_known_values)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(scaled_input)\n",
    "        future_predictions.append(prediction[0])\n",
    "        \n",
    "        # Calculate prediction standard deviation\n",
    "        # Increase uncertainty as we predict further into the future\n",
    "        base_std = np.std(model.predict(scaler.transform(X.iloc[-100:])))\n",
    "        pred_std = base_std * np.sqrt(step + 1)  # Increase std over time\n",
    "        prediction_std.append(pred_std)\n",
    "        \n",
    "        # Update last_known_values for next prediction\n",
    "        lastast_known_values = np.roll(last_known_values, -1)\n",
    "        last_known_values[0, -1] = prediction[0]\n",
    "\n",
    "# Create future dates\n",
    "last_date = df_features['date'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_steps)\n",
    "\n",
    "# Filter historical data since 2024\n",
    "start_date = datetime(2020, 1, 1)\n",
    "historical_data = df_features[df_features['date'] >= start_date]\n",
    "\n",
    "# Calculate confidence intervals\n",
    "confidence_interval = 0.95\n",
    "z_score = norm.ppf((1 + confidence_interval) / 2)\n",
    "lower_bound = [pred - z_score * std for pred, std in zip(future_predictions, prediction_std)]\n",
    "upper_bound = [pred + z_score * std for pred, std in zip(future_predictions, prediction_std)]\n",
    "\n",
    "# Plot historical data and future predictions with cone of uncertainty\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(historical_data['date'], historical_data['value'], label='Historical Data', color='blue')\n",
    "plt.plot(future_dates, future_predictions, label='Future Predictions', color='red')\n",
    "plt.fill_between(future_dates, lower_bound, upper_bound, color='red', alpha=0.2, label=f'{confidence_interval*100}% Confidence Interval')\n",
    "plt.title(f\"{config['fred']['series_id']} Historical Data and Future Forecast\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(config['plot']['y_label'])\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"NN_forecast_future_with_uncertainty_cone.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print future predictions with confidence intervals\n",
    "future_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Predicted Value': future_predictions,\n",
    "    'Lower Bound': lower_bound,\n",
    "    'Upper Bound': upper_bound\n",
    "})\n",
    "\n",
    "print(\"Forecasting completed and visualizations saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc2a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c1fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869e097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
