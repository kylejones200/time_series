{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ead5a9-ce68-47b9-a108-fc48fb363a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from arch import arch_model\n",
    "\n",
    "# Stationarity Analysis\n",
    "def analyze_stationarity(series, name=\"Series\"):\n",
    "    \"\"\"Comprehensive stationarity analysis using ADF test\"\"\"\n",
    "    adf_result = adfuller(series, autolag='AIC')\n",
    "    print(f\"Stationarity Analysis for {name}\")\n",
    "    print(\"===================================\")\n",
    "    print(f'ADF Statistic: {adf_result[0]:.4f}')\n",
    "    print(f'p-value: {adf_result[1]:.4f}')\n",
    "    print('Critical values:')\n",
    "    for key, value in adf_result[4].items():\n",
    "        print(f'\\t{key}: {value:.4f}')\n",
    "    return adf_result[1] < 0.05\n",
    "\n",
    "# Cointegration Test\n",
    "def test_cointegration(y1, y2):\n",
    "    \"\"\"Test for cointegration between two time series\"\"\"\n",
    "    score, pvalue, _ = coint(y1, y2)\n",
    "    print(\"Cointegration Test Results\")\n",
    "    print(\"=========================\")\n",
    "    print(f'Test Statistic: {score:.4f}')\n",
    "    print(f'p-value: {pvalue:.4f}')\n",
    "    return pvalue < 0.05\n",
    "\n",
    "# Econometric ARIMA Model\n",
    "class EconometricARIMA:\n",
    "    def __init__(self, data, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0)):\n",
    "        self.data = data\n",
    "        self.order = order\n",
    "        self.seasonal_order = seasonal_order\n",
    "        self.model = None\n",
    "        self.results = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit SARIMA model with automatic differencing\"\"\"\n",
    "        self.model = sm.tsa.SARIMAX(self.data, order=self.order, seasonal_order=self.seasonal_order)\n",
    "        self.results = self.model.fit()\n",
    "        return self.results\n",
    "\n",
    "    def diagnostic_plots(self):\n",
    "        \"\"\"Generate diagnostic plots for model evaluation\"\"\"\n",
    "        self.results.plot_diagnostics(figsize=(15, 12))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def forecast(self, steps=10, alpha=0.05):\n",
    "        \"\"\"Generate forecasts with confidence intervals\"\"\"\n",
    "        forecast = self.results.get_forecast(steps=steps)\n",
    "        mean_forecast = forecast.predicted_mean\n",
    "        conf_int = forecast.conf_int(alpha=alpha)\n",
    "        return mean_forecast, conf_int\n",
    "\n",
    "# Econometric VAR Model\n",
    "class EconometricVAR:\n",
    "    def __init__(self, data, maxlags=None):\n",
    "        self.data = data\n",
    "        self.maxlags = maxlags\n",
    "        self.model = None\n",
    "        self.results = None\n",
    "\n",
    "    def select_order(self):\n",
    "        \"\"\"Select optimal lag order using information criteria\"\"\"\n",
    "        model = sm.tsa.VAR(self.data)\n",
    "        return model.select_order(maxlags=self.maxlags)\n",
    "\n",
    "    def fit(self, lags=None):\n",
    "        \"\"\"Fit VAR model\"\"\"\n",
    "        if lags is None:\n",
    "            lags = self.select_order().aic\n",
    "        self.model = sm.tsa.VAR(self.data)\n",
    "        self.results = self.model.fit(lags)\n",
    "        return self.results\n",
    "\n",
    "    def granger_causality(self, caused, causing, signif=0.05):\n",
    "        \"\"\"Test for Granger causality\"\"\"\n",
    "        test_result = self.results.test_causality(caused, causing, kind='f')\n",
    "        return {\n",
    "            'test_statistic': test_result.test_statistic,\n",
    "            'p_value': test_result.pvalue,\n",
    "            'significant': test_result.pvalue < signif\n",
    "        }\n",
    "\n",
    "# Volatility Analysis Class\n",
    "class VolatilityAnalysis:\n",
    "    def __init__(self, returns):\n",
    "        self.returns = returns\n",
    "        self.model = None\n",
    "        self.results = None\n",
    "\n",
    "    def fit_garch(self, p=1, q=1):\n",
    "        \"\"\"Fit GARCH(p,q) model\"\"\"\n",
    "        self.model = arch_model(self.returns, vol='Garch', p=p, q=q)\n",
    "        self.results = self.model.fit()\n",
    "        return self.results\n",
    "\n",
    "    def forecast_volatility(self, horizon=10):\n",
    "        \"\"\"Forecast volatility\"\"\"\n",
    "        forecast = self.results.forecast(horizon=horizon)\n",
    "        return forecast.variance.values[-1]\n",
    "\n",
    "    def analyze_volatility_clustering(self):\n",
    "        \"\"\"Analyze volatility clustering\"\"\"\n",
    "        squared_returns = self.returns**2\n",
    "        acf = sm.tsa.acf(squared_returns, nlags=20)\n",
    "        return acf\n",
    "\n",
    "# Error Correction Model\n",
    "class ErrorCorrectionModel:\n",
    "    def __init__(self, y, x):\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "        self.results = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit Error Correction Model\"\"\"\n",
    "        coint_reg = sm.OLS(self.y, sm.add_constant(self.x)).fit()\n",
    "        residuals = coint_reg.resid\n",
    "        dy = np.diff(self.y)\n",
    "        dx = np.diff(self.x)\n",
    "        res_lag = residuals[:-1]\n",
    "        X = sm.add_constant(np.column_stack((dx, res_lag)))\n",
    "        ecm = sm.OLS(dy, X).fit()\n",
    "        self.results = ecm\n",
    "        return self.results\n",
    "\n",
    "# Panel Analysis Class\n",
    "class PanelAnalysis:\n",
    "    def __init__(self, data, entity_col, time_col):\n",
    "        self.data = data\n",
    "        self.entity_col = entity_col\n",
    "        self.time_col = time_col\n",
    "\n",
    "    def fixed_effects(self, y_col, x_cols):\n",
    "        \"\"\"Estimate fixed effects model\"\"\"\n",
    "        model = sm.PanelOLS.from_formula(\n",
    "            f\"{y_col} ~ {'+'.join(x_cols)} + EntityEffects\",\n",
    "            data=self.data.set_index([self.entity_col, self.time_col])\n",
    "        )\n",
    "        return model.fit()\n",
    "\n",
    "    def random_effects(self, y_col, x_cols):\n",
    "        \"\"\"Estimate random effects model\"\"\"\n",
    "        model = sm.RandomEffects.from_formula(\n",
    "            f\"{y_col} ~ {'+'.join(x_cols)}\",\n",
    "            data=self.data.set_index([self.entity_col, self.time_col])\n",
    "        )\n",
    "        return model.fit()\n",
    "\n",
    "# Economic Indicator Analysis\n",
    "def analyze_economic_indicators():\n",
    "    gdp = pd.read_csv('gdp_data.csv', parse_dates=['date'], index_col='date')\n",
    "    inflation = pd.read_csv('inflation_data.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "    gdp_stationary = analyze_stationarity(gdp['value'], 'GDP')\n",
    "    inf_stationary = analyze_stationarity(inflation['value'], 'Inflation')\n",
    "    cointegrated = test_cointegration(gdp['value'], inflation['value'])\n",
    "\n",
    "    if gdp_stationary and inf_stationary:\n",
    "        model = EconometricVAR(pd.concat([gdp, inflation], axis=1))\n",
    "        results = model.fit()\n",
    "        granger_results = model.granger_causality('gdp', 'inflation')\n",
    "    else:\n",
    "        ecm = ErrorCorrectionModel(gdp['value'], inflation['value'])\n",
    "        results = ecm.fit()\n",
    "\n",
    "    vol_analysis = VolatilityAnalysis(gdp.pct_change().dropna())\n",
    "    garch_results = vol_analysis.fit_garch()\n",
    "    \n",
    "    return results, granger_results, garch_results\n",
    "\n",
    "# Structural Breaks Detection\n",
    "def detect_structural_breaks(series, max_breaks=5):\n",
    "    \"\"\"Detect structural breaks using Bai-Perron test\"\"\"\n",
    "    from statsmodels.stats.diagnostic import breaks_cusumolsresid\n",
    "    scores, pvals = breaks_cusumolsresid(series)\n",
    "    return scores, pvals\n",
    "\n",
    "# Seasonal Adjustment\n",
    "def seasonal_adjustment(series):\n",
    "    \"\"\"Perform seasonal adjustment using X-13 ARIMA-SEATS\"\"\"\n",
    "    return sm.tsa.x13_arima_analysis(series)\n",
    "\n",
    "# Handling Missing Data\n",
    "def handle_missing_economic_data(df):\n",
    "    \"\"\"Handle missing values in economic time series\"\"\"\n",
    "    df_interp = df.interpolate(method='cubic')\n",
    "    df_filled = df_interp.fillna(method='ffill')\n",
    "    return df_filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1babcc6-9297-4f83-9f58-3bb5830a23da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
